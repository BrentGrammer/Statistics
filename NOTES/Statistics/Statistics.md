# Descriptive Statistics vs. Inferential Statistics

## Descriptive Statistics

- Describes the characteristics of a dataset
  - Mean, median, mode
  - Variance
  - Kurtosis, skew
  - Distribution shape
  - Spectrum
- No relation from the sample to the population; no generalization to other datasets or groups
- No comparison of the characteristics of one dataset to the characteristics of another dataset
- The main point is to have a few characteristics that describe the features of a particular set of data, i.e. just to characterize a dataset.

## Inferential Statistics

- Using features of a dataset to make claims about the population from which it was drawn
  - P-value
  - T/F/chi-square values
  - Confidence intervals
  - Hypothesis testing
- Purpose is to relate data features to populations or generalize to other datasets/groups
- Comparing values between datasets/groups to generalize results from a sample to a population.

## Independent and Dependent Variables

- DV/Dependent Variable: The outcome variable, that you are trying to explain
- IV: Independent Variable: Explanatory variables, that you hope will explain the DV. Independent vars explain the dependent vars.
  - Can be either what you control or things you observe in the real world that explain the DV
  - Example: Effect of soil moisture on plant growth: Soil Growth is the independent variable (what we can change), plant growth is the DV
- Good practice to stick the independent variable on the x-axis and the outcome/dependent variable on the y-axis.

### MODELS

- Purpose is to focus on certain features and abstract away complexity we are not interested in.
- A model is an equation or a set of equations that explains a feature in a dataset.
  - Example: Trying to understand why someone is a certain height. The model would be a simplified version of reality where IVs are gender,parents height,childhood nutrition etc.
- **Residuals** ($\varepsilon$) - a term that is added on to the model called the residual or error (represents the differences in height that are not explained by our simplified set of variables)
  - Example: We subtract the model from the real data and see what the error is (the residual). If it is small then the model can be considered good, if it is larger than the model is a bad model and doesn't fit reality.
- The goal is to get the Residuals to be small (small error), but the models should be as simple as possible!
  - It can be a balance: when the model is too simple, the residual gets too large, but when the residual is too small it could mean that the model is too complex (taking in all sorts of variables etc.)
  - NOTE: The model also needs to be relevant! (If the model has nothing to do with reality/data then the residual will be zero, but the model in this case tells us nothing useful.)

